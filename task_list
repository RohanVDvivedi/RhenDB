 PICKED TASKS

  1.* heap_table
   * heap_table_root {uint64_t free_space_tree_root_page_id, uint64_t heap_pages_tree_root_page_id}
   * we will need 2 bplus_trees
     * free_space_tree, key = (free_space, page_id) -> in volatile memory protected by a rwlock
     * heap_pages_tree, key = (page_id) -> possibly persistent on disk, inside a mintxengine protected by deadlock avoider btree lock
   * free_space_tree has to be volatile, and stores (free_space, page_id)
   * heap_pages_tree has to be persistent ACID, and stores (page_id)
   * heap_pages_tree works just like any other index, except indexes point to (page_id, tuple_index) instead of just (page_id)
   * free space tree is just an hint in volatile memory for the best page to accomodate a new tuple, its contents will not always be consistent with the heap pages tree
   * free_space_tree is only used to find a page with enough free space to the next incomming tuple, presence of this page must be verified using the heap_pages_tree, free_sapce_tree is just a hint
   * scan over the complete table only scans all the pages in the order of their page_id-s using the heap_pages_tree
   * there will be a function called get_page_with_enough_space to get a page and insert a tuple on it, this function will also be responsible to rebuild the free space tree when it finds plenty of wrong entries
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page, heap_pages_tree is just like another index
   * while accessing the free_space_tree rules apply to access and always lock in the following order, free_space_tree->heap_pages_tree->heap_page
   * single rwlock (LockKing) for free_space_tree and mintxengine managed latches and locks for heap_pages_tree

 Design and api
   * get_heap_page_with_enough_free_space()
     * read lock free_space_tree, and maintain the list of skipped entries
     * iterate over all entries where free_space >= desired value
     * for each page_id open a scan to make sure it exists in heap_pages_tree, if not skip this entry
     * with this scan open, write lock the page itself
     * if it does not have enough free space skip this entry
     * else read unlock the free_space_tree, release scan on heap_pages tree and return locked page
     * if end of free_space_tree is reached, create a new heap page, insert it in heap_pages_tree and return that
     * but before that write_lock free_space_tree remove all skipped entries and the entry for the page that we just locked and found the free space in
   * notify_heap_page_to_free_space_tree(page_id, free_space)
     * inserts an entry in free_space_tree, with write_lock held
     * call this function after you release any lock where you may have modified the heap_page, at any point after acquiring it
   * simple raw b+tree iterator to get heap_pages in order from heap_pages_tree in order of their page_ids
     * get_new_heap_table_iterator(page_id, tuple_index) -> we start at some page_id >= page_id in the parameter
     * get_curr_heap_page() -> to get page
     * get_curr_heap_tuple() -> to get tuple
     * next_heap_page()
     * next_heap_tuple()
     * delete_heap_table_iterator()
 **** it would be deadlock prone to acquire index (or heap_pages_tree) latches after already holding some heap_page with a latch, PONDER

 2.* define catalog tables and indexes on it - persistent
   * same as indexes and heap_tables

 3.0* implement SQL parser (possibly in a different directory)
 3.1* implement query plan tree
   * with operators
 3.2* implement relational algebra operators
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> with/without indexes
   * joins -> with/without indexes
   * union, set difference and intersection

 3.* define statistics tables - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 4.* lock table (using VolatilePageStore)
 * attributes
   * resource_type - uint16_t
   * resource_id - uint256 -> table_id or row_id (page_id, tuple_index)
   * lock_mode (SHARED, EXCLUSIVE and many more) uint16_t
   * lock_status (WAITING or HELD) 1 bit
   * transaction_id (uint256 id of the transaction)
   * timestamp (creation of this entry, for wait timeouts) -> new entry to be created for lock_mode change from WAITING -> HELD
 * indexes
   * free_space_tree (free_space, page_id) => mandatory
   * transaction_id -> lock (to find all locks held and release them upon a commit or abort) => mandatory
   * resource_type, resource_id, lock_mode, lock_status -> lock (to find all contentions to acquire new locks AND to detect deadlocks)
   * think about more indexes as per accesses
 * this work can be delayed we can solely rely on mintxengine and MVCC rules to give us the snapshot isolation that we desire

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it