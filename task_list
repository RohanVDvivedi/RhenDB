 PICKED TASKS

 * add a hashtable to map transaction_ids to transaction structs and protect it under active_transactions_lock, lock is taken to only insert itself in it and remove right after we mark ourselves completed (committed or aborted)
 * implement query_plan callback for the lock_manager, to wait and to wakeup/notify
 * query_plan structure holds pointers to rhendb and the transaction struct

 * even selection and projection functions can be implemented as a synchronous operators (think about it)

 * make typed_user_value also hold where does it store it's extended bytes, and upon freeing free them too (for volatile page store)
 * selection and projection may instead be implemented using a complex transformer, how about we use python as a scripting tool to do this
   * the current design is limited to using only 1 operand for each comparison from 1 tuple OR just sinply combine a few non constant field tuples into 1 attribute into a single output tuple's attribute for projection, which is a very limited usecase
 * a selection or projection can be a single transformer statement (selection compare the output, if it NULL or ZERO it is considered as false)
 * a user defined function can be a series of transformers applied one after the another over a set of local variables
 * basically implement a RVM (RhenDB Virtual Machine)
 * that basically takes a transformer and converts it into C code function, then we compile it into binary machine code and execute it, like in JIT machines

  * what operators to implement
    * scan on b+tree/hash index (sort rids (per 1 or set of buckets for hash index OR about some 1000 pages for bplus tree) and then scan the table), scan on table(start and move ahead linearly)
    * sort (external sorting, N-way)
    * joins (nested loop with per block, index nested loop, sort merge join, hash join)
    * group_by (based on hash or sorted input data otherwise)

 1.0* implement SQL parser (possibly in a different directory)
 1.1* implement query plan tree
   * with operators
   * need functions to compare, and hash, including extended data types from tuple large types, two positons inside tuples or a tuple position and a materialized value, like materialized numeric
 1.2* implement relational algebra operators
   * use BoomPar's resource usage limiter to allot a mini transaction only if the buffer count it needs is available
   * every transaction starts with reservng 2 frames to access the transaction table
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> implement external sorting, by using a temp_tuple_store
   * joins -> with/without indexes (hashjoins using a temp_tuple_store as buckets)
   * union, set difference and intersection

 2.* define catalog tables and indexes on it - persistent
   * stores only serialized immutable datatypes dti-s and things like bplus_tree_tuple_defs and persistent serialized immutable query_plans/functions and an LRU cache on them
   * there will also be reference counters for all of them, with LRU searches on them using name, index and their own pointers
   * they also point to each other, dtis pointing to other dtis in there and bplus_tree_tuple_defs and alike, pointing to record_defs that are dtis in there itself
   * functions and queries and functions can call other functions, reference them
   * we will use reference counting to already cached catalog objects, implement on_destroy and on_reference callbacks of type static_type_info_callback-s, that increment and decrement the reference counter for the dtis, that need to be passed around

 3.* define statistics tables (*future) - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 4.* lock table remaining tasks (*future)
   * deadlock detection and resolution task job (*future, for now rely on timeouts to back off and abort)
   * define basic lock martix for row, heap_table (ordering_lock), simple reader writer lock (*future, do it when query optimizer and catalog tables are ready )

 5.*selection implement optimize function

 6.*implement various types of transformers
   * boolean(convert NULL and ZERO to false and rest everything is true)
   * sign(negatives to -1, 0 to 0, and positives to 1)
   * compare(for comparing any types)
   * add, sub, mul, divide, mod, gcd, lcm, pow, sin, cos, multiplicate inverse, additive inverse
   * strings and blobs to be concatenated, substring with from and to
   * unix epoch to date, day, month, year, second, millisecond, microsecond, with timezones
   * build more complex functions transformers with local variables and bytecode stored in context
   * length of string, blob, array, tuple, etc

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it
