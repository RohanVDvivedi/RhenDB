 PICKED TASKS

 1.* lock table
   * deadlock detection and resolution task job (*future, for now rely on timeouts to back off and abort)
   * define basic lock martix for row, heap_table (ordering_lock), simple reader writer lock (*future, do it when query optimizer and catalog tables are ready )

 2.* giant_tuple_def, an in-memory tuple_def for an on-disk tuple_def (containing worms)
   * conversion function to convert on-disk tuple_def to giant_tuple_def
   * conversion function to convert on-disk tuple to giant_tuple
   * use this giant_tuple_def's tuples for in-memory tuples
   * compute max_size for this tuples using tuplestore, and also limit max element_count for the complete project as a macro

 3.* temp_tuple_store (name it this instead of intermediate_tuple_store)
   * stores tuples or giant_tuples sequentially one after the another and reads them back like from a stream and deletes this temp file on closing
   * struct intermediate_tuple_store {
        pthread_mutex_t lock;
        uint64_t in_memory_size; // next_insert_offset crossing this value spill to the temp file
        uint64_t curr_file_size; // if non zero use fd instead
        int fd; // temp file, if next_insert_offset > in_memory_size
        void* md;
        uint64_t next_insert_offset; -> more appropriate name append_offset
     }
   * struct tuple_region {
        uint64_t region_offset; // always multiple of page size
        void* region_memory; // NULL if uninitialized
        uint64_t region_size; // capped by curr_file_size

        void* tuple; // offset of this tuple in the memory = (tuple - region_memory)
        const tuple_size_def* tpl_sz_d;
     } -> utility function to get memory_before_tuple, memory_at_tuple and memory_after_tuple in uint64_t bytes
   * void initializes_intermediate_tuple_store(intermediate_tuple_store* its_p, uint64_t in_memory_size)
   * int read_tuple(tuple_region* tr_p, uint32_t offset, const tuple_size_def* tpl_sz_d, uint32_t* next_offset);
   * struct write_iterator{
      its_p;

      uint64_t region_offset; // always multiple of page size
      void* region_memory; // NULL if uninitialized
      uint64_t region_size; // capped by curr_file_size

      void* tuple; // offset of this tuple in the memory = (tuple - region_memory)
      const tuple_size_def* tpl_sz_d;
   }
   * get_new_intermediate_tuple_store_write_iterator();
   * void* get_tuple(uint32_t* offset, uint32_t* size, const tuple_size_def* tpl_sz_d, int finalize_prior_tuple); // offset is output, size is in-out request bytes and you get greater than or equal to that bytes at the offset, extending the file if necessary
   * finalize_prior_tuple, moves the next_insert_offset forward
   * delete_write_iterator();


 4.* define catalog tables and indexes on it - persistent
   * same as indexes and heap_tables
   * prilimnary investigation revealed no-MVCC and no-per-tuple-locking, instead per table locking, do more research

 5.0* implement SQL parser (possibly in a different directory)
 5.1* implement query plan tree
   * with operators
 5.2* implement relational algebra operators
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> implement external giant_tuple_def sorting, by using a tuple_file
   * joins -> with/without indexes (hashjoins using a tuple_file)
   * union, set difference and intersection
    * Operators will be of two types
      * Scan -> run on mini transaction engine's thread pool, heap_table scan, index scan, etc
        -> accesses data from the database
        -> they accumulate tuples and push them when pulled
        -> they can be put to sleep and stopped at any instant and can be restarted, this checks are made every iteration
        -> they are source of the data
      * Transformers -> Operators that select, project, sort, join tuples -> they run on the transaction's thread pool or IO thread pool
        -> accesses data from the input stream to them, possibly a intermediate tuple store
        -> they just pull tuples, when their parent operator pulls on them
        -> they sleep and do nothing when we do not pull from these operators
        -> they are mere but smart transformers

 6.* define statistics tables (*future) - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it