 PICKED TASKS

  1.* heap_table
   * heap_table_root {uint64_t free_space_tree_root_page_id, uint64_t heap_pages_tree_root_page_id}
   * we will need 2 bplus_trees
     * free_space_tree, key = (free_space, page_id) -> in volatile memory protected by a rwlock
     * heap_pages_tree, key = (page_id) -> possibly persistent on disk, inside a mintxengine protected by deadlock avoider btree lock
   * free_space_tree has to be volatile, and stores (free_space, page_id)
   * heap_pages_tree has to be persistent ACID, and stores (page_id)
   * heap_pages_tree works just like any other index, except indexes point to (page_id, tuple_index) instead of just (page_id)
   * free space tree is just an hint in volatile memory for the best page to accomodate a new tuple, its contents will not always be consistent with the heap pages tree
   * free_space_tree is only used to find a page with enough free space to the next incomming tuple, presence of this page must be verified using the heap_pages_tree, free_sapce_tree is just a hint
   * scan over the complete table only scans all the pages in the order of their page_id-s using the heap_pages_tree
   * there will be a function called get_page_with_enough_space to get a page and insert a tuple on it, this function will also be responsible to rebuild the free space tree when it finds plenty of wrong entries
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page, heap_pages_tree is just like another index
   * while accessing the free_space_tree rules apply to access and always lock in the following order, free_space_tree->heap_pages_tree->heap_page
   * single rwlock (LockKing) for free_space_tree and mintxengine managed latches and locks for heap_pages_tree

 Design and api
   * separate module/directory heap_table
   * struct heap_table_definition
   {
      rwlock free_space_tree_lock; // to be locked for only the free space tree
      uint64_t free_space_tree_root_page_id;
      bplus_tree_tuple_defs* free_space_tree_defs;
      rage_engine* free_space_tree_engine; // volatile engine, preferrably volatilepagestore

      uint64_t heap_pages_tree_root_page_id; // should be passed externally and not to be part of tuple defs of heap_table
      bplus_tree_tuple_defs* heap_pages_tree_defs;
      rage_engine* heap_pages_tree_engine; // persistent acid engine, preferrably mintxengine

      tuple_def* row_def; // first element must be mvcc_header

      async_free_space_executor_thread; // executes free space tree operations, for functions with async prefix
      async_free_space_executor_queue<{INSERT/REMOVE, free_space, page_id}>; // value arraylist, it will trigger when it is full

      async_heap_pagees_executor_thread;
      async_heap_pages_executor_queue<{REMOVE, page_id}>;
   };
   * async functions that operate only using the write lock on the free_space_tree_lock, on a separate thread
   * async_remove_from_free_space_tree(uint32_t free_space, uint64_t page_id);
   * async_insert_in_free_space_tree(uint32_t free_space, uint64_t page_id);
   * persistent_page get_heap_page_with_enough_free_space(uint32_t free_space); // async_removes entries that do not exist in heap_pages_tree, of that do not have enough free space then a remove and insert is also asynced, runs everything in a read only mode, only uses the transaction_id for locking the heap_page itself, iterates until the end of the free_space tree, after which it allocates a new heap_page and returns that instead
   * get_new_heap_table_iterator(uint64_t page_id, uint32_t tuple_index); // heap_pages_tree always scans in leaf-only read-locked traversal, heap_pages are the only ones that could be write locked here
   * get_curr_heap_page_id();
   * get_curr_heap_page();
   * get_curr_heap_tuple_index();
   * get_curr_heap_tuple();
   * next_heap_page_heap_table_iterator();
   * next_heap_tuple_heap_table_iterator();
   * clone_heap_table_iterator();
   * delete_heap_table_iterator();
   * if you modify the heap_page please perform async_remove/insert for free space tree
   * we need a bulk_job_executor, using value_arraylist and a periodic_job, that works at fixed intervals or immediately when the queue is full in boompar OR does it using a fixed maximum thread count cached thread pool executor for both the rage_engine-s

 2.* define catalog tables and indexes on it - persistent
   * same as indexes and heap_tables

 3.0* implement SQL parser (possibly in a different directory)
 3.1* implement query plan tree
   * with operators
 3.2* implement relational algebra operators
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> with/without indexes
   * joins -> with/without indexes
   * union, set difference and intersection

 3.* define statistics tables - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 4.* lock table (using VolatilePageStore)
 * attributes
   * resource_type - uint16_t
   * resource_id - uint256 -> table_id or row_id (page_id, tuple_index)
   * lock_mode (SHARED, EXCLUSIVE and many more) uint16_t
   * lock_status (WAITING or HELD) 1 bit
   * transaction_id (uint256 id of the transaction)
   * timestamp (creation of this entry, for wait timeouts) -> new entry to be created for lock_mode change from WAITING -> HELD
 * indexes
   * free_space_tree (free_space, page_id) => mandatory
   * transaction_id -> lock (to find all locks held and release them upon a commit or abort) => mandatory
   * resource_type, resource_id, lock_mode, lock_status -> lock (to find all contentions to acquire new locks AND to detect deadlocks)
   * think about more indexes as per accesses
 * this work can be delayed we can solely rely on mintxengine and MVCC rules to give us the snapshot isolation that we desire

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it