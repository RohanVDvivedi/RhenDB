 PICKED TASKS

 2.0* implement SQL parser (possibly in a different directory)
 2.1* implement query plan tree
   * with operators
 2.2* implement relational algebra operators
   * use BoomPar's resource usage limiter to allot a mini transaction only if the buffer count it needs is available
   * every transaction starts with reservng 2 frames to access the transaction table
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> implement external giant_tuple_def sorting, by using a tuple_file
   * joins -> with/without indexes (hashjoins using a tuple_file)
   * union, set difference and intersection
    * Operators will be of two types
      * Scan -> run on mini transaction engine's thread pool, heap_table scan, index scan, etc
        -> accesses data from the database
        -> they accumulate tuples and push them when pulled
        -> they can be put to sleep and stopped at any instant and can be restarted, this checks are made every iteration
        -> they are source of the data
      * Transformers -> Operators that select, project, sort, join tuples -> they run on the transaction's thread pool or IO thread pool
        -> accesses data from the input stream to them, possibly a intermediate tuple store
        -> they just pull tuples, when their parent operator pulls on them
        -> they sleep and do nothing when we do not pull from these operators
        -> they are mere but smart transformers
    * the complete query plan will execute in a fixed sized thread pool, where we define operators that can be preempted while storing their current scan state and exit when they are asked to or when their work is completed and there are no tuples to consume from ,i.e. their chidlren are also completed
    * they can also be woken up by their children or parent operators by using atomic function and can be asked to stop
    * their internal interface will look something like this
     typedef struct operator {
        uint64_t operator_index; // asked to be used by the user's thread

        pthread_mutex_t output_lock;
        linkedlist<temp_tuple_store> output;

        pthread_mutex_t state_lock;
        int is_running; // is set when running
        int is_completed; // can be set only once
        int is_shutdown_called; // if set the operator must go into completed state

        int schedule(uint64_t tuples_to_produce, uint64_t bytes_to_produce);
        int shutdown();
        int run(operator* op);

        void* operator_context; // everything that this operator needs to do including its state is stored here
     }
     user thread will store list of all operators and their indices

 3.* define catalog tables and indexes on it - persistent
   * stores only serialized immutable datatypes dti-s and things like bplus_tree_tuple_defs and persistent serialized immutable query_plans/functions and an LRU cache on them
   * there will also be reference counters for all of them, with LRU searches on them using name, index and their own pointers
   * they also point to each other, dtis pointing to other dtis in there and bplus_tree_tuple_defs and alike, pointing to record_defs that are dtis in there itself
   * functions and queries and functions can call other functions, reference them
   * we will use reference counting to already cached catalog objects, implement on_destroy and on_reference callbacks of type static_type_info_callback-s, that increment and decrement the reference counter for the dtis, that need to be passed around

 4.* define statistics tables (*future) - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 5.* lock table remaining tasks (*future)
   * deadlock detection and resolution task job (*future, for now rely on timeouts to back off and abort)
   * define basic lock martix for row, heap_table (ordering_lock), simple reader writer lock (*future, do it when query optimizer and catalog tables are ready )

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it
