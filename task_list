 PICKED TASKS

 * we need a query structure / transaction structure, that holds all operators and operator_buffers, has a mutex to put operators in paused state waiting on operators or locked data, helping orchestrating
 * implement operator and its buffer basic functions

 * starting with relational algebra operators
  * typed_user_value
    * typedef struct typed_user_value {
      data_type_info* type;
      user_value value;
    }
  * transformers
    * typedef struct transformer
      {
        const void* context;
        typed_user_value (*transform)(const void* context, uint32_t input_count, const typed_user_value** input);
      }
      typed_user_value transform(transformer* t, const typed_user_value* input);
      integral operations, logical and, or, not, bitwise and or not, math add, sub, mul divide, compare (returns 1, 0, -1),
      strings/blobs, get suffix/prefix, compare
      integral integer seconds, milliseconds, microseconds, nanoseconds to date and time, and its parts
  * selection
      struct selection_params
      {
        selection_tree* tree;
        tuple_def* lvalue_def;
      }
      struct selection_tree
      {
        enum {
          NOT, -> class 0
          AND, OR, XOR -> class 1
          EQUALS, NOT_EQUALS, GREATER_THAN, LESSER_THAN, GREATER_THAN_EQUALS, LESSER_THAN_EQAULS -> class 2
          LVALUE, -> class 3
          RVALUE, -> class 4
        }

        union
        {
          selection* not_for; // class 0
          singlylist<selection*> logical_for; // class 1
          // class 2
          { // class 3
            transformer* lvalue_transform;
            static_position lvalue_position;
          }
          user_value rvalue; // class 4
        }
      }
    * int select(const void* tuple, const selection_params* sp);
  * projection
      struct projection_params
      {
        int projection_count;
        projection projection_list[];
      }
      struct projection
      {
        static_position output_position;
        transformer combiner_transformer;
        static_position* input_positions;
      }
    * void* project(const void* tuple, uint64_t page_id, uint32_t tuple_index, const void* page, const projection_params* pp);

  * what operators to implement
    * scan on b+tree/hash index (sort rids and then scan the table), scan on table(start and move ahead linearly)
    * sort (external sorting, N-way)
    * joins (nested loop with per block, index nested loop, sort merge join, hash join)
    * group_by (based on hash or sorted input data otherwise)

 1.0* implement SQL parser (possibly in a different directory)
 1.1* implement query plan tree
   * with operators
   * need functions to compare, and hash, including extended data types from tuple large types, two positons inside tuples or a tuple position and a materialized value, like materialized numeric
 1.2* implement relational algebra operators
   * use BoomPar's resource usage limiter to allot a mini transaction only if the buffer count it needs is available
   * every transaction starts with reservng 2 frames to access the transaction table
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> implement external sorting, by using a temp_tuple_store
   * joins -> with/without indexes (hashjoins using a temp_tuple_store as buckets)
   * union, set difference and intersection

 2.* define catalog tables and indexes on it - persistent
   * stores only serialized immutable datatypes dti-s and things like bplus_tree_tuple_defs and persistent serialized immutable query_plans/functions and an LRU cache on them
   * there will also be reference counters for all of them, with LRU searches on them using name, index and their own pointers
   * they also point to each other, dtis pointing to other dtis in there and bplus_tree_tuple_defs and alike, pointing to record_defs that are dtis in there itself
   * functions and queries and functions can call other functions, reference them
   * we will use reference counting to already cached catalog objects, implement on_destroy and on_reference callbacks of type static_type_info_callback-s, that increment and decrement the reference counter for the dtis, that need to be passed around

 3.* define statistics tables (*future) - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 4.* lock table remaining tasks (*future)
   * deadlock detection and resolution task job (*future, for now rely on timeouts to back off and abort)
   * define basic lock martix for row, heap_table (ordering_lock), simple reader writer lock (*future, do it when query optimizer and catalog tables are ready )

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it
