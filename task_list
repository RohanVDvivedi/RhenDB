 PICKED TASKS

 1.* lock table (using VolatilePageStore)
 * attributes
   * resource_type - uint16_t
   * resource_id - uint256 -> table_id or row_id (page_id, tuple_index)
   * transaction_id (uint256 id of the transaction)
   * lock_type (HEAP_TABLE_ORDERING_LOCK(for scan and vaccum of heap tables), SEQUENCE_LOCK(for auto-increment), RWLOCK, MUTEX, etc and many more, whose lock compatibility matrix can be registered at runtime at any time) uint32_t
   * lock_mode (SHARED, EXCLUSIVE and many more depending on the lock_type supported by lock_type) uint16_t
   * lock_status (WAITING or HELD) 1 bit
   * updated_at_in_seconds (creation of this entry in clock monotonic seconds, for wait timeouts and deadlocks) uint64_t
 * rules
   * lock_type with its lock compatibility matrix has to be loaded at runtime right before application starts, you may use glock matric from LockKing
   * resource_type, resource_id may not be confined to just one type of lock_type, like a heap_table may have ordering and sequence locks locked at once, along with other locks that we may need in serializable isolation level
 * structure
   * protected using a global rwlock
   * heap_table to hold all lock entries
   * transaction_id -> lock (to find all locks held and release them upon a commit or abort) => mandatory
   * resource_type, resource_id, lock_type -> lock (to find all contentions to acquire new locks AND to detect deadlocks)
 * api
   * try_acquire_lock(transaction_id, resource_type, resource_id, lock_type, lock_mode)
   * acquire_lock(transaction_id, resource_type, resource_id, lock_type, lock_mode)
   * change_lock_mode(transaction_id, resource_type, resource_id, lock_type, lock_mode_old, lock_mode_new)
   * release_lock(transaction_id, resource_type, resource_id, lock_type, lock_mode)
   * release_all_locks(transaction_id)
 * identified locks
   * ordering_lock on heap_table shared mode in scan and exclusive mode for fixing the accumulated entries
   * sequence_lock on btree indexes for shared mode for all accesses and exclusive more for auto increments
   * row locks on rows to allow serializable isolation in the future

 2.* define catalog tables and indexes on it - persistent
   * same as indexes and heap_tables
   * prilimnary investigation revealed no-MVCC and no-per-tuple-locking, instead per table locking, do more research

 3.* giant_tuple_def, an in-memory tuple_def for an on-disk tuple_def (containing worms)
   * conversion function to convert on-disk tuple_def to giant_tuple_def
   * conversion function to convert on-disk tuple to giant_tuple
   * use this giant_tuple_def's tuples for in-memory tuples
   * compute max_size for this tuples using tuplestore, and also limit max element_count for the complete project as a macro

 4.* tuple_file structure
   * stores tuples or giant_tuples sequentially one after the another and reads them back like from a stream and deletes this temp file on closing
   * reading can be done as a stream
   * write can also be done as a stream, returning the offset in the file for this tuple
   * file stays all in-memory up until a point, over which it spills to the disk, and then is accessed from there
   * no tuple updates allowed
   * also allows read-only mapping to mmap pages containing a tuple, and operate on it as if it is all in memory
   * usefull for external sorting, hash joins and passing intermediate tuples between different operators

 5.0* implement SQL parser (possibly in a different directory)
 5.1* implement query plan tree
   * with operators
 5.2* implement relational algebra operators
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> implement external giant_tuple_def sorting, by using a tuple_file
   * joins -> with/without indexes (hashjoins using a tuple_file)
   * union, set difference and intersection

 6.* define statistics tables - persistent and possibly in a different database
   * same as indexes and heap_tables (low priority)

 * Design methodology
   * we will use postgresql architecture over (mysql like) mini transactions
   * we will have heaps for storing tables, insert to which gives us a page_id (physical page_id) and a tuple_index (slot no) in that page
   * indexes will always include the page_id, tuple_index in the index key right after the actual key columns, and the index entry will be index key followed by the covering columns
   * standard latch rules apply index->heap_page, heap_pages_tree->heap_page
   * inserts/deletes will always be done to heap in a single mini transaction one at a time
     * inserts/deletes to indexes will be done in mini transactions not owned by anyone
   * updates are just delete followed by insert into the heap
   * reads will be be done without mini transactions, but in a fixed number of them
   * there will be vaccum, like postgresql
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?, is_xmin_aborted?, is_xmax_aborted?
     * xmin, xmax will be as wide as transaction_table suggests
     * the *? are advisory bitmaps and should be kept updated when ever a heap page is being read (if only a read lock on page is held then let another writer do it asynchronously) or written
   * we will never chain mini transactions for a high level transaction, we will just ensure that the transactions read only the data that is visible to them, and vaccum out invisible rows
   * lock_tables -> need to think over it